{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT",
      "provenance": [],
      "authorship_tag": "ABX9TyNEEFg5FtV1n9jytOGl1H4k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08dd9ba110ff4ce0aeb1c8ecc18b6aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_760b5d9c36fa47de80d0786ee4adf74d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_24b1c488fd5e4122ab393a078b3e17ad",
              "IPY_MODEL_1d0b568a8c744bfea3f2b96f63e808cc",
              "IPY_MODEL_22c7cff75019448bbeebcb1221d95574"
            ]
          }
        },
        "760b5d9c36fa47de80d0786ee4adf74d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24b1c488fd5e4122ab393a078b3e17ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_806a2797e53040bb8a9228f0b071b80c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a01303d1499243d8acf8045feda5bb37"
          }
        },
        "1d0b568a8c744bfea3f2b96f63e808cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af22683e1e004fba988bc1f5f62e2d7c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_161f2bc4cc2f44399c9317431baf32c5"
          }
        },
        "22c7cff75019448bbeebcb1221d95574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c3974659bd0e4d59a816ce45ebac5720",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 714M/714M [00:17&lt;00:00, 38.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a17ed8372b6493292a4a7342d8fde8a"
          }
        },
        "806a2797e53040bb8a9228f0b071b80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a01303d1499243d8acf8045feda5bb37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af22683e1e004fba988bc1f5f62e2d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "161f2bc4cc2f44399c9317431baf32c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3974659bd0e4d59a816ce45ebac5720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a17ed8372b6493292a4a7342d8fde8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbinibini/Deep-Learning-Paper-Review-and-Practice/blob/main/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcw6ykwa_uA7"
      },
      "source": [
        "#https://riverkangg.github.io/nlp/nlp-bertWordEmbedding/\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SLLAXmNAHG5"
      },
      "source": [
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceNTMjKaARC6"
      },
      "source": [
        "text = \"임베딩을 시도할 문장이다.\"\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hNn1zhwvA4R7",
        "outputId": "5cae34a2-aaa1-4a7a-84c5-56dc632d5c63"
      },
      "source": [
        "marked_text"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] 임베딩을 시도할 문장이다. [SEP]'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmS5FUoqA3OL",
        "outputId": "0d534fc3-31ec-47d3-f5ee-c34dcea8be48"
      },
      "source": [
        "# Tokenize our sentence with the BERT tokenizer.\n",
        "tokenized_text = tokenizer.tokenize(marked_text) #WordPiece 모델을 사용\n",
        "print(tokenized_text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '임', '##베', '##딩', '##을', '시', '##도', '##할', '문', '##장이', '##다', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqxcCZCHBcQL"
      },
      "source": [
        "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
        "text = \"배를 타고 여행을 간다.\" \\\n",
        "       \"추석에 먹은 배가 맛있었다.\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub69X4LjBjZd"
      },
      "source": [
        "# Add the special tokens.\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iolepr0XBkxB",
        "outputId": "ead76e07-1ac3-4903-f381-d983c8ae915a"
      },
      "source": [
        "# Split the sentence into tokens.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "tokenized_text"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " '배',\n",
              " '##를',\n",
              " '타',\n",
              " '##고',\n",
              " '여',\n",
              " '##행을',\n",
              " '간',\n",
              " '##다',\n",
              " '.',\n",
              " '추',\n",
              " '##석',\n",
              " '##에',\n",
              " '먹',\n",
              " '##은',\n",
              " '배',\n",
              " '##가',\n",
              " '맛',\n",
              " '##있',\n",
              " '##었다',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9OZMptOBl2_",
        "outputId": "59669993-70bb-4594-d5c3-b7aa5edae791"
      },
      "source": [
        "# Map the token strings to their vocabulary indeces.\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "indexed_tokens"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 9330,\n",
              " 11513,\n",
              " 9845,\n",
              " 11664,\n",
              " 9565,\n",
              " 88904,\n",
              " 8845,\n",
              " 11903,\n",
              " 119,\n",
              " 9765,\n",
              " 40958,\n",
              " 10530,\n",
              " 9266,\n",
              " 10892,\n",
              " 9330,\n",
              " 11287,\n",
              " 9254,\n",
              " 119192,\n",
              " 17706,\n",
              " 119,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfqP4dHWBqWd",
        "outputId": "a420169f-8af8-4ed2-fce7-cafa9a49aeee"
      },
      "source": [
        "# Display the words with their indeces.\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]           101\n",
            "배             9,330\n",
            "##를          11,513\n",
            "타             9,845\n",
            "##고          11,664\n",
            "여             9,565\n",
            "##행을         88,904\n",
            "간             8,845\n",
            "##다          11,903\n",
            ".               119\n",
            "추             9,765\n",
            "##석          40,958\n",
            "##에          10,530\n",
            "먹             9,266\n",
            "##은          10,892\n",
            "배             9,330\n",
            "##가          11,287\n",
            "맛             9,254\n",
            "##있          119,192\n",
            "##었다         17,706\n",
            ".               119\n",
            "[SEP]           102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p12grZOgB0Uf",
        "outputId": "b80dc12d-a617-41ff-e5ea-0477cc880317"
      },
      "source": [
        "# Mark each of the 29 tokens as belonging to sentence \"1\".\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "print (segments_ids)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG014Fk0B9oO"
      },
      "source": [
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy-QZEPrCBSr",
        "outputId": "f9270487-feee-4af7-c1e2-6bbcfdfa6d89"
      },
      "source": [
        "tokens_tensor"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   101,   9330,  11513,   9845,  11664,   9565,  88904,   8845,  11903,\n",
              "            119,   9765,  40958,  10530,   9266,  10892,   9330,  11287,   9254,\n",
              "         119192,  17706,    119,    102]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7eQPy02CCoE",
        "outputId": "4ea1eb80-d6d3-4778-d309-dcf7914b2ad1"
      },
      "source": [
        "segments_tensors"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "08dd9ba110ff4ce0aeb1c8ecc18b6aed",
            "760b5d9c36fa47de80d0786ee4adf74d",
            "24b1c488fd5e4122ab393a078b3e17ad",
            "1d0b568a8c744bfea3f2b96f63e808cc",
            "22c7cff75019448bbeebcb1221d95574",
            "806a2797e53040bb8a9228f0b071b80c",
            "a01303d1499243d8acf8045feda5bb37",
            "af22683e1e004fba988bc1f5f62e2d7c",
            "161f2bc4cc2f44399c9317431baf32c5",
            "c3974659bd0e4d59a816ce45ebac5720",
            "9a17ed8372b6493292a4a7342d8fde8a"
          ]
        },
        "id": "T0Sp878jCfku",
        "outputId": "609f2124-925e-41f8-85cb-613340b9c94c"
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-multilingual-cased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08dd9ba110ff4ce0aeb1c8ecc18b6aed",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6e7QbKTCEkE"
      },
      "source": [
        "# Run the text through BERT, and collect all of the hidden states produced\n",
        "# from all 12 layers. \n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "\n",
        "    # Evaluating the model will return a different number of objects based on \n",
        "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "    # becase we set `output_hidden_states = True`, the third item will be the \n",
        "    # hidden states from all layers. See the documentation for more details:\n",
        "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "    hidden_states = outputs[2]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBAvKqokCz1L",
        "outputId": "129ee530-ee8d-4b6a-d0d1-3fb85b23788b"
      },
      "source": [
        "outputs[0].size() #last_hidden_state"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 22, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGL0bp5_C5SZ",
        "outputId": "c620b398-6bb9-410f-be8a-f897141fbaf2"
      },
      "source": [
        "outputs[1].size() #pooler_output"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyZhhwsrDIFM",
        "outputId": "6a4a7365-e9e1-4ea4-a173-7bb8010525f4"
      },
      "source": [
        "len(outputs[2]) #hidden_states"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6KiwIGADI-q",
        "outputId": "9b32e868-0049-4cd3-d534-a7d09b0610b6"
      },
      "source": [
        "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
            "Number of batches: 1\n",
            "Number of tokens: 22\n",
            "Number of hidden units: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "ctB3cmDUENMk",
        "outputId": "6bb50f26-7d14-4c1b-884c-eea0a8b28a63"
      },
      "source": [
        "# For the 5th token in our sentence, select its feature values from layer 5.\n",
        "token_i = 5\n",
        "layer_i = 5\n",
        "vec = hidden_states[layer_i][batch_i][token_i]\n",
        "\n",
        "# Plot the values as a histogram to show their distribution.\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.hist(vec, bins=200)\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A59gmqMEcNq",
        "outputId": "106dce42-d008-4128-bb96-a6255f5398cc"
      },
      "source": [
        "# `hidden_states` is a Python list.\n",
        "print('      Type of hidden_states: ', type(hidden_states))\n",
        "\n",
        "# Each layer in the list is a torch tensor.\n",
        "print('Tensor shape for each layer: ', hidden_states[0].size())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Type of hidden_states:  <class 'tuple'>\n",
            "Tensor shape for each layer:  torch.Size([1, 22, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ0bai6xEfQZ",
        "outputId": "9aec4d24-3672-4d66-885c-fac29fa8ed56"
      },
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor.\n",
        "# 레이어별로 값을 그룹화하는 것이 모델에 적합하지만, 단어 임베딩을 위해 토큰별로 그룹화한다.\n",
        "# 레이어를 결합해서 하나의 큰 텐서를 만든다.\n",
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 1, 22, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JURjwXEcEtaJ",
        "outputId": "8eba11ad-29e0-46c3-c6b9-9e02c7f309cb"
      },
      "source": [
        "#“batches” 차원은 필요하지 않으므로 제거한다.\n",
        "# Remove dimension 1, the \"batches\".\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 22, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOsgBMyUE8WS",
        "outputId": "270b5fc2-7055-4a4d-8d25-03e4a627d3f4"
      },
      "source": [
        "#마지막으로 permute를 사용하여 “layers” 및 “tokens” 차원을 전환할 수 있다.\n",
        "# Swap dimensions 0 and 1.\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([22, 13, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odZILSh0E-sH"
      },
      "source": [
        "#각 토큰에 대한 개별 벡터 또는 전체 문장의 단일 벡터 표현을 얻고 싶지만, \n",
        "#입력의 각 토큰에 대해 각각 768 크기의 13개의 개별 벡터가 있다.\n",
        "#개별 벡터를 얻으려면 일부 레이어 벡터를 결합해야한다.\n",
        "#하지만 몇 가지 합리적인 접근 방식을 시도해보고, 추가로 살펴볼 수 있는 몇 가지 유용한 리소스를 소개한다."
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMoCS4ZCH7tS"
      },
      "source": [
        " ##### Word Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks2SleH2FloP",
        "outputId": "e7a2ec35-1101-4ba2-ef1e-2884a47fe602"
      },
      "source": [
        "# 먼저 마지막 4개의 레이어를 연결하여(concatenate) 토큰 당 단일 단어 벡터를 제공한다. \n",
        "# 각 벡터의 길이는 4 x 768 = 3,072\n",
        "# Stores the token vectors, with shape [36 x 3,072]\n",
        "token_vecs_cat = []\n",
        "\n",
        "# `token_embeddings` is a [36 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "    \n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Concatenate the vectors (that is, append them together) from the last \n",
        "    # four layers.\n",
        "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "    \n",
        "    # Use `cat_vec` to represent `token`.\n",
        "    token_vecs_cat.append(cat_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape is: 22 x 3072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khQVcS7YFmzK",
        "outputId": "3a091a65-5db5-4a87-b12f-6dde69e8fc72"
      },
      "source": [
        "#다른 방법으로 마지막 4개의 레이어를 합산하여(summing) 단어 벡터를 만든다.\n",
        "# Stores the token vectors, with shape [36 x 768]\n",
        "token_vecs_sum = []\n",
        "\n",
        "# `token_embeddings` is a [36 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "\n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Sum the vectors from the last four layers.\n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "    \n",
        "    # Use `sum_vec` to represent `token`.\n",
        "    token_vecs_sum.append(sum_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape is: 22 x 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0p9umXgH1jK"
      },
      "source": [
        "#### Sentence Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwPdnU38H3U-",
        "outputId": "f574c308-8301-49cb-c2c2-21691686159c"
      },
      "source": [
        "# 전체 문장에 대한 단일 벡터를 얻기 위해 여러 application-dependent 전략이 있지만, \n",
        "# 간단한 접근 방식은 단일 768 크기의 벡터를 생성하는 각 토큰의 두번째에서 \n",
        "# 마지막 숨겨진 레이어를 평균내는 것이다.\n",
        "\n",
        "# `hidden_states` has shape [13 x 1 x 36 x 768]\n",
        "\n",
        "# `token_vecs` is a tensor with shape [36 x 768]\n",
        "token_vecs = hidden_states[-2][0]\n",
        "\n",
        "# Calculate the average of all 36 token vectors.\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "sentence_embedding.size()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG_Hej-oIl8B"
      },
      "source": [
        "##### 상황에 따라 달라지는지 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1mRwEubIAJx",
        "outputId": "b4b254d3-f7c6-47b1-fbe7-e9ed7aa2e1a1"
      },
      "source": [
        "for i, token_str in enumerate(tokenized_text):\n",
        "  print (i, token_str)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [CLS]\n",
            "1 배\n",
            "2 ##를\n",
            "3 타\n",
            "4 ##고\n",
            "5 여\n",
            "6 ##행을\n",
            "7 간\n",
            "8 ##다\n",
            "9 .\n",
            "10 추\n",
            "11 ##석\n",
            "12 ##에\n",
            "13 먹\n",
            "14 ##은\n",
            "15 배\n",
            "16 ##가\n",
            "17 맛\n",
            "18 ##있\n",
            "19 ##었다\n",
            "20 .\n",
            "21 [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XbCETN1IqJ3"
      },
      "source": [
        "# '배' 라는 단어는 1, 15에 있다.\n",
        "#  이 분석에서는 마지막 4 개의 레이어를 합산하여 만든 단어 벡터를 사용"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_taiazPoJECa",
        "outputId": "1cfcedcd-a550-4908-dc68-ee63904271ce"
      },
      "source": [
        "len(token_vecs_sum)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqWdXrt9IzC8",
        "outputId": "81e88b61-6601-43c0-b547-c295aa0c77ce"
      },
      "source": [
        "print('First 5 vector values for each instance of \"배\".')\n",
        "print('')\n",
        "print(\" 배를 타다\", str(token_vecs_sum[1][:5]))\n",
        "print(\"과일 배  \", str(token_vecs_sum[15][:5]))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 vector values for each instance of \"배\".\n",
            "\n",
            " 배를 타다 tensor([-3.8934, -3.9059, -1.5779,  2.4786,  2.2829])\n",
            "과일 배   tensor([-3.3566, -2.3208, -4.7532,  0.5019,  3.6503])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPFsoitGLaEd"
      },
      "source": [
        "#더 정확한 비교를 위해 벡터 간의 코사인 유사성을 계산\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Calculate the cosine similarity between the word 배 \n",
        "# in \"배를 타다\" vs \"배를 먹다\" (different meanings).\n",
        "diff_배 = 1 - cosine(token_vecs_sum[1], token_vecs_sum[15])\n",
        "\n",
        "# Calculate the cosine similarity between the word 배\n",
        "# in \"배를 타다\" vs \"바다에 있는 배\" (same meaning).\n",
        "same_배 = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
        "\n",
        "print('Vector similarity for  *similar*  meanings:  %.2f' % same_배)\n",
        "print('Vector similarity for *different* meanings:  %.2f' % diff_배)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2RToRT0LiGD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
